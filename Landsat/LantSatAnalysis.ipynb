{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as cs\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OccupancyData = pd.read_csv(\"lantsat.csv\")\n",
    "\n",
    "w_features=OccupancyData.iloc[:,np.arange(len(OccupancyData.columns) - 1)].copy()\n",
    "w_target= OccupancyData.iloc[:,len(OccupancyData.columns) - 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames in this wise manner yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "def feature_process(features):\n",
    "\n",
    "    w_features_num = features;\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('selector', DataFrameSelector(list(w_features_num))),\n",
    "            ('imputer', Imputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler(with_mean = False)),\n",
    "        ])\n",
    "\n",
    "    full_pipeline = num_pipeline\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = feature_process(w_features)\n",
    "\n",
    "feature_prepared = pd.DataFrame(data=full_pipeline.fit_transform(w_features),index=np.arange(1,len(w_features) + 1))\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_results = w_target[:int(0.8 * len(w_target))]\n",
    "test_results = w_target[int(0.8 * len(w_target)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:    9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=51,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the decision tree is : 82.42%.\n",
      "******************************************************* \n",
      "The F1 score using the decision tree is : 0.82.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:   13.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees ?\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(10, 100)), 'min_samples_split': [2,3,4,5]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the decision tree is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the decision tree is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=89,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the Random Forest is : 87.00%.\n",
      "******************************************************* \n",
      "The F1 score using the Random Forest is : 0.87.\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the Random Forest is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Random Forest is : {:.2f}.\".format(f1_score(test_results,T_predict,average='micro'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the Naive Bayes is : 61.83%.\n",
      "******************************************************* \n",
      "The F1 score using the Navie Bayes is : 0.62.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
    "model.fit(train_data, train_results)\n",
    "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the Naive Bayes is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Navie Bayes is : {:.2f}.\".format(f1_score(test_results,T_predict,average='micro'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the Perceptron is : 52.00%.\n",
      "******************************************************* \n",
      "The F1 score using the Perceptron is : 0.52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuhualong/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perception \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(alpha=1)\n",
    "model.fit(train_data, train_results)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the Perceptron is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Perceptron is : {:.2f}.\".format(f1_score(test_results,T_predict,average='micro'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='uniform')\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the Nearest Neighbour Classifer is : 88.33%.\n",
      "******************************************************* \n",
      "The F1 score using the Nearest Neighbour Classifer is : 0.88.\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbour Classifer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "params = {'leaf_size': list(range(10, 50)), 'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "grid_search_cv = GridSearchCV(KNeighborsClassifier(), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the Nearest Neighbour Classifer is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Nearest Neighbour Classifer is : {:.2f}.\".format(f1_score(test_results,T_predict,average='micro'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................... kernel=rbf, C=1, score=0.89625, total=   0.2s\n",
      "[CV] kernel=rbf, C=1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... kernel=rbf, C=1, score=0.89125, total=   0.2s\n",
      "[CV] kernel=rbf, C=1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ kernel=rbf, C=1, score=0.890556597874, total=   0.2s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] .................... kernel=rbf, C=2, score=0.9025, total=   0.2s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ................... kernel=rbf, C=2, score=0.89875, total=   0.2s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.898061288305, total=   0.2s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] .................... kernel=rbf, C=4, score=0.9025, total=   0.2s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] .................. kernel=rbf, C=4, score=0.904375, total=   0.2s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.905565978737, total=   0.2s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] .................. kernel=rbf, C=8, score=0.905625, total=   0.2s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ................... kernel=rbf, C=8, score=0.90625, total=   0.2s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.905565978737, total=   0.2s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] .................... kernel=rbf, C=16, score=0.905, total=   0.2s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ................. kernel=rbf, C=16, score=0.915625, total=   0.2s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.909943714822, total=   0.2s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ................. kernel=rbf, C=32, score=0.904375, total=   0.2s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ................. kernel=rbf, C=32, score=0.915625, total=   0.2s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.914321450907, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=KFold(n_splits=3, random_state=1, shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['rbf'], 'C': [1, 2, 4, 8, 16, 32]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=3)\n",
      "_________________###################____________________\n",
      "The prediction accuracy using the SVC is : 88.08%.\n",
      "******************************************************* \n",
      "The F1 score using the SVC is : 0.88.\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['rbf'], 'C': [ 2**x for x in range(0,6) ]},\n",
    "    ]\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=inner_cv,  n_jobs=1, scoring='accuracy',verbose=3)\n",
    "grid_search.fit(train_data, train_results)\n",
    "clf=grid_search.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search.predict(test_data)\n",
    "print grid_search\n",
    "print('_________________###################____________________')\n",
    "print(\"The prediction accuracy using the SVC is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "print('******************************************************* ')\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the SVC is : {:.2f}.\".format(f1_score(test_results,T_predict,average='micro'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
