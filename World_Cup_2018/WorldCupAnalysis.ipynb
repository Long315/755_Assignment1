{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as cs\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcup=pd.read_csv(\"2018 worldcup.csv\",index_col=0)\n",
    "#match date is assumed to be irrelevant for the match results\n",
    "worldcup.drop(['Date','Team1_Ball_Possession(%)'],axis=1,inplace=True)\n",
    "#worldcup.describe()\n",
    "train_wc = worldcup[:int(len(worldcup))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#world cup attributes\n",
    "w_features=train_wc.iloc[:,np.arange(26)].copy()\n",
    "#world cup goal result\n",
    "w_goals=train_wc.iloc[:,26].copy()\n",
    "#wordl cup match result\n",
    "w_results=train_wc.iloc[:,27].copy()\n",
    "\n",
    "len(train_wc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames in this wise manner yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(features):\n",
    "\n",
    "    w_features_num = features.drop(['Location','Phase','Team1','Team2','Team1_Continent','Team2_Continent','Normal_Time'], axis=1,inplace=False)\n",
    "    w_features_cat= features[['Location','Phase','Team1','Team2','Team1_Continent','Team2_Continent','Normal_Time']].copy()\n",
    "\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('selector', DataFrameSelector(list(w_features_num))),\n",
    "            ('imputer', Imputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler(with_mean = False)),\n",
    "        ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "            ('selector', DataFrameSelector(list(w_features_cat))),\n",
    "            ('cat_encoder', cs.OneHotEncoder(drop_invariant=True)),\n",
    "        ])\n",
    "\n",
    "    full_pipeline = FeatureUnion(transformer_list=[\n",
    "            (\"num_pipeline\", num_pipeline),\n",
    "            (\"cat_pipeline\", cat_pipeline),\n",
    "        ])\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = feature_process(w_features)\n",
    "\n",
    "feature_prepared = pd.DataFrame(data=full_pipeline.fit_transform(w_features),index=np.arange(1,len(w_features) + 1))\n",
    "\n",
    "worldcup_cleaned=pd.concat([feature_prepared,w_goals.to_frame(), w_results.to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_goals = w_goals[:int(0.8 * len(w_goals))]\n",
    "test_goals = w_goals[int(0.8 * len(w_goals)):]\n",
    "\n",
    "model = LinearRegression(n_jobs = None)\n",
    "model.fit(train_data, train_goals)\n",
    "T_predict = model.predict(test_data)\n",
    "W_predict = model.predict(train_data)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "_________________###################____________________\n",
      "Mean squared error for testing data: 5.29\n",
      "Variance score for testing data: -1.57\n",
      "******************************************************* \n",
      "Mean squared error for training data: 0.00\n",
      "Variance score for training data: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print(' ')\n",
    "# The coefficients\n",
    "#print('Coefficients and Intercept are: ', model.coef_,\"   \",model.intercept_,' respectively')\n",
    "# The mean squared error\n",
    "print('_________________###################____________________')\n",
    "print(\"Mean squared error for testing data: %.2f\"\n",
    "      % mean_squared_error(test_goals, T_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for testing data: %.2f' % r2_score(test_goals, T_predict))\n",
    "print('******************************************************* ')\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(train_goals, W_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for training data: %.2f' % r2_score(train_goals, W_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Linear Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(train_data, train_goals)\n",
    "T_predict = model.predict(test_data)\n",
    "W_predict = model.predict(train_data)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "_________________###################____________________\n",
      "Mean squared error for testing data: 3.98\n",
      "Variance score for testing data: -0.93\n",
      "******************************************************* \n",
      "Mean squared error for training data: 0.15\n",
      "Variance score for training data: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "# The coefficients\n",
    "#print('Coefficients and Intercept are: ', model.coef_,\"   \",model.intercept_,' respectively')\n",
    "# The mean squared error\n",
    "print('_________________###################____________________')\n",
    "print(\"Mean squared error for testing data: %.2f\"\n",
    "      % mean_squared_error(test_goals, T_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for testing data: %.2f' % r2_score(test_goals, T_predict))\n",
    "print('******************************************************* ')\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(train_goals, W_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for training data: %.2f' % r2_score(train_goals, W_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best')\n",
      "The prediction accuracy using the decision tree is : 53.85%.\n",
      "The F1 score using the decision tree is : 0.45.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phase</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Team1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Team1_Continent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Team1_Attempts</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Team1_Corners</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Team1_Offsides</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Team1_Pass_Accuracy(%)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Team1_Distance_Covered</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team1_Ball_Recovered</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Team1_Yellow_Card</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Team1_Red_Card</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Team1_Fouls</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Team2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Team2_Continent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Team2_Attempts</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Team2_Corners</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Team2_Offsides</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Team2_Ball_Possession(%)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Team2_Pass_Accuracy(%)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Team2_Distance_Covered</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Team2_Ball_Recovered</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Team2_Yellow_Card</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Team2_Red_Card</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Team2_Fouls</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Normal_Time</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Importance\n",
       "0                   Location         1.0\n",
       "1                      Phase         0.0\n",
       "2                      Team1         0.0\n",
       "3            Team1_Continent         0.0\n",
       "4             Team1_Attempts         0.0\n",
       "5              Team1_Corners         0.0\n",
       "6             Team1_Offsides         0.0\n",
       "7     Team1_Pass_Accuracy(%)         0.0\n",
       "8     Team1_Distance_Covered         0.0\n",
       "9       Team1_Ball_Recovered         0.0\n",
       "10         Team1_Yellow_Card         0.0\n",
       "11            Team1_Red_Card         0.0\n",
       "12               Team1_Fouls         0.0\n",
       "13                     Team2         0.0\n",
       "14           Team2_Continent         0.0\n",
       "15            Team2_Attempts         0.0\n",
       "16             Team2_Corners         0.0\n",
       "17            Team2_Offsides         0.0\n",
       "18  Team2_Ball_Possession(%)         0.0\n",
       "19    Team2_Pass_Accuracy(%)         0.0\n",
       "20    Team2_Distance_Covered         0.0\n",
       "21      Team2_Ball_Recovered         0.0\n",
       "22         Team2_Yellow_Card         0.0\n",
       "23            Team2_Red_Card         0.0\n",
       "24               Team2_Fouls         0.0\n",
       "25               Normal_Time         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DesicionTree For Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_results = w_results[:int(0.8 * len(w_results))]\n",
    "test_results = w_results[int(0.8 * len(w_results)):]\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the decision tree is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the decision tree is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n",
    "\n",
    "fi1 = zip(w_features.columns, grid_search_cv.best_estimator_.feature_importances_)\n",
    "fi1.sort(key = lambda x:-x[1])\n",
    "pd.DataFrame(fi1, columns=[\"Feature\",\"Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:   13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=8,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "The prediction accuracy using the random forest is : 38.46%.\n",
      "The F1 score using the decision tree is : 0.36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Team1_Continent</td>\n",
       "      <td>0.148568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Location</td>\n",
       "      <td>0.102880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Team1_Ball_Recovered</td>\n",
       "      <td>0.072329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Team2_Ball_Possession(%)</td>\n",
       "      <td>0.067682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Team2_Continent</td>\n",
       "      <td>0.047551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Team2_Corners</td>\n",
       "      <td>0.044898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Team1_Distance_Covered</td>\n",
       "      <td>0.040233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Team1_Fouls</td>\n",
       "      <td>0.037818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Team1_Red_Card</td>\n",
       "      <td>0.033207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team2_Attempts</td>\n",
       "      <td>0.029985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Team1_Attempts</td>\n",
       "      <td>0.029220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Team1_Offsides</td>\n",
       "      <td>0.027456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Team1_Corners</td>\n",
       "      <td>0.020131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Team2_Ball_Recovered</td>\n",
       "      <td>0.014451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Team1</td>\n",
       "      <td>0.013655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Team1_Yellow_Card</td>\n",
       "      <td>0.006983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Phase</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Team1_Pass_Accuracy(%)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Team2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Team2_Offsides</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Team2_Pass_Accuracy(%)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Team2_Distance_Covered</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Team2_Yellow_Card</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Team2_Red_Card</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Team2_Fouls</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Normal_Time</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Importance\n",
       "0            Team1_Continent    0.148568\n",
       "1                   Location    0.102880\n",
       "2       Team1_Ball_Recovered    0.072329\n",
       "3   Team2_Ball_Possession(%)    0.067682\n",
       "4            Team2_Continent    0.047551\n",
       "5              Team2_Corners    0.044898\n",
       "6     Team1_Distance_Covered    0.040233\n",
       "7                Team1_Fouls    0.037818\n",
       "8             Team1_Red_Card    0.033207\n",
       "9             Team2_Attempts    0.029985\n",
       "10            Team1_Attempts    0.029220\n",
       "11            Team1_Offsides    0.027456\n",
       "12             Team1_Corners    0.020131\n",
       "13      Team2_Ball_Recovered    0.014451\n",
       "14                     Team1    0.013655\n",
       "15         Team1_Yellow_Card    0.006983\n",
       "16                     Phase    0.000000\n",
       "17    Team1_Pass_Accuracy(%)    0.000000\n",
       "18                     Team2    0.000000\n",
       "19            Team2_Offsides    0.000000\n",
       "20    Team2_Pass_Accuracy(%)    0.000000\n",
       "21    Team2_Distance_Covered    0.000000\n",
       "22         Team2_Yellow_Card    0.000000\n",
       "23            Team2_Red_Card    0.000000\n",
       "24               Team2_Fouls    0.000000\n",
       "25               Normal_Time    0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest For Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_results = w_results[:int(0.8 * len(w_results))]\n",
    "test_results = w_results[int(0.8 * len(w_results)):]\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the random forest is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the decision tree is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n",
    "\n",
    "fi1 = zip(w_features.columns, grid_search_cv.best_estimator_.feature_importances_)\n",
    "fi1.sort(key = lambda x:-x[1])\n",
    "pd.DataFrame(fi1, columns=[\"Feature\",\"Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "The prediction accuracy using the Navie Bayes is : 61.54%.\n",
      "The F1 score using the decision tree is : 0.51.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes For Classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(train_data, train_results)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print(\"The prediction accuracy using the Navie Bayes is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Naive Bayes is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "The prediction accuracy using the Perceptron is : 23.08%.\n",
      "The F1 score using the decision tree is : 0.09.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuhualong/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perceptron For Classification\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(alpha=1)\n",
    "model.fit(train_data, train_results)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print(\"The prediction accuracy using the Perceptron is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Perceptron is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 398 tasks      | elapsed:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "The prediction accuracy using the Nearest Neighbour Classifer is : 15.38%.\n",
      "The F1 score using the decision tree is : 0.08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbour Classifer For Classification\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "params = {'leaf_size': list(range(10, 50)), 'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "grid_search_cv = GridSearchCV(KNeighborsClassifier(), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the Nearest Neighbour Classifer is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Nearest Neighbour Classifer is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.470588235294, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.176470588235, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.411764705882, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.235294117647, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.235294117647, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.294117647059, total=   0.0s\n",
      "GridSearchCV(cv=KFold(n_splits=3, random_state=1, shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['rbf'], 'C': [1, 2, 4, 8, 16, 32]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=3)\n",
      "The prediction accuracy using the SVC is : 23.08%.\n",
      "The F1 score using the Nearest Neighbour Classifer is : 0.10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# SVC For Classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['rbf'], 'C': [ 2**x for x in range(0,6) ]},\n",
    "    ]\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=inner_cv,  n_jobs=1, scoring='accuracy',verbose=3)\n",
    "grid_search.fit(train_data, train_results)\n",
    "clf=grid_search.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search.predict(test_data)\n",
    "print grid_search\n",
    "print(\"The prediction accuracy using the SVC is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "# F1 score: 1 is perfect prediction\n",
    "print(\"The F1 score using the Nearest Neighbour Classifer is : {:.2f}.\".format(f1_score(test_results,T_predict,average='weighted'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
