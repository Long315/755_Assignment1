{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as cs\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcup=pd.read_csv(\"2018 worldcup.csv\",index_col=0)\n",
    "#match date is assumed to be irrelevant for the match results\n",
    "worldcup.drop(['Date','Team1_Ball_Possession(%)'],axis=1,inplace=True)\n",
    "#worldcup.describe()\n",
    "train_wc = worldcup[:int(len(worldcup))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#world cup attributes\n",
    "w_features=train_wc.iloc[:,np.arange(26)].copy()\n",
    "#world cup goal result\n",
    "w_goals=train_wc.iloc[:,26].copy()\n",
    "#wordl cup match result\n",
    "w_results=train_wc.iloc[:,27].copy()\n",
    "\n",
    "len(train_wc.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames in this wise manner yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(features):\n",
    "\n",
    "    w_features_num = features.drop(['Location','Phase','Team1','Team2','Team1_Continent','Team2_Continent','Normal_Time'], axis=1,inplace=False)\n",
    "    w_features_cat= features[['Location','Phase','Team1','Team2','Team1_Continent','Team2_Continent','Normal_Time']].copy()\n",
    "\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('selector', DataFrameSelector(list(w_features_num))),\n",
    "            ('imputer', Imputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler(with_mean = False)),\n",
    "        ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "            ('selector', DataFrameSelector(list(w_features_cat))),\n",
    "            ('cat_encoder', cs.OneHotEncoder(drop_invariant=True)),\n",
    "        ])\n",
    "\n",
    "    full_pipeline = FeatureUnion(transformer_list=[\n",
    "            (\"num_pipeline\", num_pipeline),\n",
    "            (\"cat_pipeline\", cat_pipeline),\n",
    "        ])\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = feature_process(w_features)\n",
    "\n",
    "feature_prepared = pd.DataFrame(data=full_pipeline.fit_transform(w_features),index=np.arange(1,len(w_features) + 1))\n",
    "\n",
    "worldcup_cleaned=pd.concat([feature_prepared,w_goals.to_frame(), w_results.to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=3, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_goals = w_goals[:int(0.8 * len(w_goals))]\n",
    "test_goals = w_goals[int(0.8 * len(w_goals)):]\n",
    "\n",
    "model = LogisticRegression(max_iter = 3)\n",
    "model.fit(train_data,train_goals)\n",
    "T_predict = model.predict(test_data)\n",
    "W_predict = model.predict(train_data)\n",
    "\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "_________________###################____________________\n",
      "Mean squared error for testing data: 2.15\n",
      "Variance score for testing data: -0.05\n",
      "******************************************************* \n",
      "Mean squared error for training data: 2.22\n",
      "Variance score for training data: 0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print(' ')\n",
    "# The coefficients\n",
    "#print('Coefficients and Intercept are: ', model.coef_,\"   \",model.intercept_,' respectively')\n",
    "# The mean squared error\n",
    "print('_________________###################____________________')\n",
    "print(\"Mean squared error for testing data: %.2f\"\n",
    "      % mean_squared_error(test_goals, T_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for testing data: %.2f' % r2_score(test_goals, T_predict))\n",
    "print('******************************************************* ')\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(train_goals, W_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for training data: %.2f' % r2_score(train_goals, W_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(n_jobs = None)\n",
    "model.fit(train_data, train_goals)\n",
    "T_predict = model.predict(test_data)\n",
    "W_predict = model.predict(train_data)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "_________________###################____________________\n",
      "Mean squared error for testing data: 5.29\n",
      "Variance score for testing data: -1.57\n",
      "******************************************************* \n",
      "Mean squared error for training data: 0.00\n",
      "Variance score for training data: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print(' ')\n",
    "# The coefficients\n",
    "#print('Coefficients and Intercept are: ', model.coef_,\"   \",model.intercept_,' respectively')\n",
    "# The mean squared error\n",
    "print('_________________###################____________________')\n",
    "print(\"Mean squared error for testing data: %.2f\"\n",
    "      % mean_squared_error(test_goals, T_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for testing data: %.2f' % r2_score(test_goals, T_predict))\n",
    "print('******************************************************* ')\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(train_goals, W_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for training data: %.2f' % r2_score(train_goals, W_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Linear Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(train_data, train_goals)\n",
    "T_predict = model.predict(test_data)\n",
    "W_predict = model.predict(train_data)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "_________________###################____________________\n",
      "Mean squared error for testing data: 3.98\n",
      "Variance score for testing data: -0.93\n",
      "******************************************************* \n",
      "Mean squared error for training data: 0.15\n",
      "Variance score for training data: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "# The coefficients\n",
    "#print('Coefficients and Intercept are: ', model.coef_,\"   \",model.intercept_,' respectively')\n",
    "# The mean squared error\n",
    "print('_________________###################____________________')\n",
    "print(\"Mean squared error for testing data: %.2f\"\n",
    "      % mean_squared_error(test_goals, T_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for testing data: %.2f' % r2_score(test_goals, T_predict))\n",
    "print('******************************************************* ')\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(train_goals, W_predict))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score for training data: %.2f' % r2_score(train_goals, W_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:    1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best')\n",
      "The prediction accuracy using the decision tree is : 53.85%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "# DesicionTree For Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_results = w_results[:int(0.8 * len(w_results))]\n",
    "test_results = w_results[int(0.8 * len(w_results)):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the decision tree is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:    7.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=8,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "The prediction accuracy using the random forest is : 38.46%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   16.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest For Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data = feature_prepared[:int(0.8 * len(feature_prepared))]\n",
    "test_data = feature_prepared[int(0.8 * len(feature_prepared)):]\n",
    "train_results = w_results[:int(0.8 * len(w_results))]\n",
    "test_results = w_results[int(0.8 * len(w_results)):]\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the random forest is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "The prediction accuracy using the Navie Bayes is : 61.54%.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(train_data, train_results)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print(\"The prediction accuracy using the Navie Bayes is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "The prediction accuracy using the Perceptron is : 23.08%.\n"
     ]
    }
   ],
   "source": [
    "# Perception \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(alpha=1)\n",
    "model.fit(train_data, train_results)\n",
    "\n",
    "T_predict = model.predict(test_data)\n",
    "print model\n",
    "print(\"The prediction accuracy using the Perceptron is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 712 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "The prediction accuracy using the Perceptron is : 15.38%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbour Classifer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "params = {'leaf_size': list(range(10, 50)), 'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "grid_search_cv = GridSearchCV(KNeighborsClassifier(), params, n_jobs=-1, verbose=1)\n",
    "grid_search_cv.fit(train_data, train_results)\n",
    "print grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search_cv.predict(test_data)\n",
    "print(\"The prediction accuracy using the Perceptron is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.470588235294, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ............ kernel=rbf, C=1, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.176470588235, total=   0.0s\n",
      "[CV] kernel=rbf, C=2 .................................................\n",
      "[CV] ............ kernel=rbf, C=2, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=4 .................................................\n",
      "[CV] ............ kernel=rbf, C=4, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.411764705882, total=   0.0s\n",
      "[CV] kernel=rbf, C=8 .................................................\n",
      "[CV] ............ kernel=rbf, C=8, score=0.352941176471, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.235294117647, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=16 ................................................\n",
      "[CV] ........... kernel=rbf, C=16, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.235294117647, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.294117647059, total=   0.0s\n",
      "[CV] kernel=rbf, C=32 ................................................\n",
      "[CV] ........... kernel=rbf, C=32, score=0.294117647059, total=   0.0s\n",
      "GridSearchCV(cv=KFold(n_splits=3, random_state=1, shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['rbf'], 'C': [1, 2, 4, 8, 16, 32]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=3)\n",
      "The prediction accuracy using the Perceptron is : 23.08%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['rbf'], 'C': [ 2**x for x in range(0,6) ]},\n",
    "    ]\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=inner_cv,  n_jobs=1, scoring='accuracy',verbose=3)\n",
    "grid_search.fit(train_data, train_results)\n",
    "clf=grid_search.best_estimator_\n",
    "\n",
    "\n",
    "T_predict = grid_search.predict(test_data)\n",
    "print grid_search\n",
    "print(\"The prediction accuracy using the Perceptron is : {:.2f}%.\".format(100*accuracy_score(test_results, T_predict)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
